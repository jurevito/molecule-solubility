{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import deepchem as dc\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Convolutional Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load esol dataset from csv\n",
    "tasks = ['measured log solubility in mols per litre']\n",
    "loader = dc.data.CSVLoader(tasks=tasks, feature_field=\"smiles\", featurizer=dc.feat.ConvMolFeaturizer())\n",
    "dataset = loader.create_dataset('esol.csv')\n",
    "\n",
    "# split esol dataset\n",
    "splitter = dc.splits.RandomSplitter()\n",
    "train_set, test_set = splitter.train_test_split(dataset, frac_train=0.8, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    'batch_size': [32, 16],\n",
    "    'graph_conv_layers': [[64, 64], [128, 128], [256, 256]],\n",
    "    'dense_layer_size': [256, 128],\n",
    "    'dropout': [0.0],\n",
    "}\n",
    "\n",
    "search_results, (batch_size, conv_layers, layer_sizes, dropout_rate) = grid_search_graph_conv(train_set, hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        rmse  batch_size conv_layers  layer_sizes  dropout_rate\n",
      "10  0.936538          16  [256, 256]          256           0.0\n",
      "11  0.939595          16  [256, 256]          128           0.0\n",
      "9   0.944217          16  [128, 128]          128           0.0\n",
      "4   0.954203          32  [256, 256]          256           0.0\n",
      "5   0.972162          32  [256, 256]          128           0.0\n",
      "7   0.982165          16    [64, 64]          128           0.0\n",
      "2   0.984718          32  [128, 128]          256           0.0\n",
      "8   0.995951          16  [128, 128]          256           0.0\n",
      "6   1.005711          16    [64, 64]          256           0.0\n",
      "3   1.017335          32  [128, 128]          128           0.0\n",
      "0   1.034305          32    [64, 64]          256           0.0\n",
      "1   1.060179          32    [64, 64]          128           0.0\n"
     ]
    }
   ],
   "source": [
    "print(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores\n",
      "{'mean-rms_score': 0.35644945087154256, 'mean-mae_score': 0.28097528781080516, 'mean-pearson_r2_score': 0.9792561778491514}\n",
      "Test scores\n",
      "{'mean-rms_score': 0.7986796892479974, 'mean-mae_score': 0.6178939486484055, 'mean-pearson_r2_score': 0.8544007404847818}\n"
     ]
    }
   ],
   "source": [
    "transformers = [dc.trans.NormalizationTransformer(transform_y=True, dataset=train_set, move_mean=True)]\n",
    "\n",
    "# preprocess data\n",
    "for transformer in transformers:\n",
    "    train_set = transformer.transform(train_set)\n",
    "    test_set = transformer.transform(test_set)\n",
    "\n",
    "# intantiate and fit model\n",
    "model = dc.models.GraphConvModel(1, mode='regression', batch_size=batch_size, graph_conv_layers=conv_layers, dense_layer_size=layer_sizes, dropout=dropout_rate)\n",
    "model.fit(train_set, nb_epoch=100)\n",
    "\n",
    "# evaluate model\n",
    "metric = [\n",
    "    dc.metrics.Metric(dc.metrics.rms_score, np.mean),\n",
    "    dc.metrics.Metric(dc.metrics.mae_score, np.mean),\n",
    "    dc.metrics.Metric(dc.metrics.pearson_r2_score, np.mean)\n",
    "]\n",
    "train_scores = model.evaluate(train_set, metric, transformers)\n",
    "test_scores = model.evaluate(test_set, metric, transformers)\n",
    "\n",
    "print(\"Train scores\")\n",
    "print(train_scores)\n",
    "\n",
    "print(\"Test scores\")\n",
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message Passing Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load esol dataset from csv\n",
    "tasks = ['measured log solubility in mols per litre']\n",
    "loader = dc.data.CSVLoader(tasks=tasks, feature_field=\"smiles\", featurizer=dc.feat.WeaveFeaturizer())\n",
    "dataset = loader.create_dataset('esol.csv')\n",
    "\n",
    "# split esol dataset\n",
    "splitter = dc.splits.RandomSplitter()\n",
    "train_set, test_set = splitter.train_test_split(dataset, frac_train=0.8, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[####################                    ]"
     ]
    }
   ],
   "source": [
    "hyper_params = {\n",
    "    'batch_size': [32, 16],\n",
    "    'n_atom_feat': [75],\n",
    "    'n_pair_feat': [14],\n",
    "    'n_hidden': [100]\n",
    "}\n",
    "\n",
    "search_results, (batch_size, n_atom_feat, n_pair_feat, n_hidden) = grid_search_mpnn(train_set, hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       rmse  batch_size  n_atom_feat  n_pair_feat  n_hidden\n",
      "1  0.655984          16           75           14       100\n",
      "0  0.685698          32           75           14       100\n"
     ]
    }
   ],
   "source": [
    "print(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores\n",
      "{'mean-rms_score': 0.33132370266898736, 'mean-mae_score': 0.2588325988489977, 'mean-pearson_r2_score': 0.9758838930741033}\n",
      "Test scores\n",
      "{'mean-rms_score': 0.5928773782943892, 'mean-mae_score': 0.4536293255027136, 'mean-pearson_r2_score': 0.9237314639815634}\n"
     ]
    }
   ],
   "source": [
    "transformers = [dc.trans.NormalizationTransformer(transform_y=True, dataset=train_set, move_mean=True)]\n",
    "\n",
    "# preprocess data\n",
    "for transformer in transformers:\n",
    "    train_set = transformer.transform(train_set)\n",
    "    test_set = transformer.transform(test_set)\n",
    "\n",
    "# intantiate and fit model\n",
    "model = dc.models.MPNNModel(1, mode='regression', batch_size=batch_size, use_queue=False, n_atom_feat=n_atom_feat, n_pair_feat=n_pair_feat, n_hidden=n_hidden, learning_rate=0.0001, T=3, M=5)\n",
    "model.fit(train_set, nb_epoch=50, checkpoint_interval=100)\n",
    "\n",
    "# evaluate model\n",
    "metric = [\n",
    "    dc.metrics.Metric(dc.metrics.rms_score, np.mean),\n",
    "    dc.metrics.Metric(dc.metrics.mae_score, np.mean),\n",
    "    dc.metrics.Metric(dc.metrics.pearson_r2_score, np.mean)\n",
    "]\n",
    "train_scores = model.evaluate(train_set, metric, transformers)\n",
    "test_scores = model.evaluate(test_set, metric, transformers)\n",
    "\n",
    "print(\"Train scores\")\n",
    "print(train_scores)\n",
    "\n",
    "print(\"Test scores\")\n",
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load esol dataset from csv\n",
    "tasks = ['measured log solubility in mols per litre']\n",
    "loader = dc.data.CSVLoader(tasks=tasks, feature_field=\"smiles\", featurizer=dc.feat.CircularFingerprint(size=2048, radius=4))\n",
    "dataset = loader.create_dataset('esol.csv')\n",
    "\n",
    "# split esol dataset\n",
    "splitter = dc.splits.RandomSplitter()\n",
    "train_set, test_set = splitter.train_test_split(dataset, frac_train=0.8, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[####################  ]"
     ]
    }
   ],
   "source": [
    "hyper_params = {\n",
    "    'n_estimators': [100, 250, 500],\n",
    "    'criterion': ['mse', 'mae'],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "search_results, (n_estimators, criterion, max_features) = grid_search_random_forest(train_set, hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        rmse  n_estimators criterion max_features\n",
      "12  1.225431           500       mse         auto\n",
      "6   1.226358           250       mse         auto\n",
      "0   1.226689           100       mse         auto\n",
      "9   1.233063           250       mae         auto\n",
      "15  1.235029           500       mae         auto\n",
      "3   1.239940           100       mae         auto\n",
      "13  1.240248           500       mse         sqrt\n",
      "7   1.244766           250       mse         sqrt\n",
      "1   1.253478           100       mse         sqrt\n",
      "16  1.262508           500       mae         sqrt\n",
      "10  1.265118           250       mae         sqrt\n",
      "4   1.274192           100       mae         sqrt\n",
      "14  1.279299           500       mse         log2\n",
      "8   1.282334           250       mse         log2\n",
      "2   1.297865           100       mse         log2\n",
      "11  1.309369           250       mae         log2\n",
      "17  1.310112           500       mae         log2\n",
      "5   1.312742           100       mae         log2\n"
     ]
    }
   ],
   "source": [
    "print(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores\n",
      "{'mean-rms_score': 0.4557074378032759, 'mean-mae_score': 0.32590803615678415, 'mean-pearson_r2_score': 0.965785107964993}\n",
      "Test scores\n",
      "{'mean-rms_score': 1.1422869134998823, 'mean-mae_score': 0.8716654813527174, 'mean-pearson_r2_score': 0.7005435810374528}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# intantiate and fit model\n",
    "sklearn_model = RandomForestRegressor(n_estimators=n_estimators, criterion=criterion, max_features=max_features, random_state=0)\n",
    "model = dc.models.SklearnModel(sklearn_model)\n",
    "model.fit(train_set)\n",
    "\n",
    "# evaluate model\n",
    "metric = [\n",
    "    dc.metrics.Metric(dc.metrics.rms_score, np.mean),\n",
    "    dc.metrics.Metric(dc.metrics.mae_score, np.mean),\n",
    "    dc.metrics.Metric(dc.metrics.pearson_r2_score, np.mean)\n",
    "]\n",
    "train_scores = model.evaluate(train_set, metric, [])\n",
    "test_scores = model.evaluate(test_set, metric, [])\n",
    "\n",
    "print(\"Train scores\")\n",
    "print(train_scores)\n",
    "\n",
    "print(\"Test scores\")\n",
    "print(test_scores)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd4f712bdf0515c4096e7f378f6652de9b65133e68b219cf86da6448b555e669"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
